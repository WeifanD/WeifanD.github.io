---
title: "Interview Notes"
layout: post
date: 2019-01-15 11:48
image: /assets/images/markdown.jpg
headerImage: false
tag:
- Deep learning
- Machine learning
- NLP
- CV
category: blog
author: WeifanD
---


# Q&A
@(Interview)

[TOC]

## 机器学习
### XGBOOST，GBDT，RandomForest
- 集成为什么比单颗树好？
  答： n个独立的classifiers，每个输出概率p在范围0-1，合成之后的出错概率为符合binomial（n,p)分布的期望，期望np远小于p。

---
- XGBOOST，GBDT，RandomForest的比较,他们有什么共性和差异？

  答：最根本的区别是，随机森林算法使用bagging技术做出预测。 GBM采用boosting技术做预测。在bagging技术中，数据集用随机采样的方法被划分成使n个样本。然后，使用单一的学习算法，在所有样本上建模。接着利用**投票或者求平均**来组合所得到的预测。Bagging是**平行**进行的。而boosting是在第一轮的预测之后进行**迭代**，下一颗树训练上一颗树的残差，算法将分类出错的预测加高权重，使得它们可以在后续一轮中得到校正。这种给予分类出错的预测高权重的顺序过程持续进行，一直到达到停止标准为止。

  随机森林通过**减少方差**（主要方式）提高模型的精度。生成树之间是不相关的，以把方差的减少最大化。在另一方面，GBM提高了精度，同时**减少了模型的偏差**和方差。

  rf对异常值**不敏感**，自动处理缺失值，通过降低方差来提高性能，对于那种低偏差高方差的过拟合数据问题有很好的的提升效果，相对的gbdt对异常值**很敏感**，是通过降低偏差,来提高性能。

  同作为以cart树作为基分类器，rf和xgboost还支持线性分类器，xgboost的**目标函数由损失函数L和正则项组成，通过泰勒展开近似**，正则项里包含叶节点数以及每个叶节点上的score的L2的平方和，在计算划分增益时，如果gain < gamma, 不划分，gain> gamma，gamma是叶节点个数的参数划分，这相当于决策树的预剪枝。 gamma是叶节点个数的参数，大大降低过拟合的可能性。

  另外传统的GBDT在优化时，只用到了loss function的**一阶导**信息，而XGBOOST对loss function做了**Taylor展开，用到了二阶导**信息 ；XGBOOST还借用了RandomForest中的**列抽样**思想，也支持在划分节点时，只考虑部分属性（现状sklearn中的GBDT也实现了列抽样）；XGBOOST可以**自动学习出缺失值的分裂方向**，论文中的default direction（具体做法时，遍历的尝试将所有的缺失值分裂到所有方向{left or right}，split and default directions with max gain）；XGBOOST实现了**并行化**，这个并行化是特征粒度上的并行化：划分节点时，每个特征并行计算，同时每个特征的**划分节点也是并行计算**（这是加速最猛的处理）；XGBOOST只接受**连续变量**，划分特征提出了block的概念，简单的说**将排序后的特征值放在block中**，以后划分特征的时候，只需要遍历一次即可，因为决策树在处理属性值时，需要将属性值先排序，这是最耗时的步骤，而block预先存储了排序的特征值，在后续过程中可以重复利用这个结构中的数据，同时，计算每个特征的划分增益可以并行处理了Collecting statistics for each column can be parallelized,giving us a parallel algorithm for split finding!!；贪心算法在选择最佳划分方式时需要遍历所有的划分点子集，在数据非常大时，这会非常低效，xgboost提出了近似直方图计算，根据数据的二阶导信息进行排序，提出一些候选划分点子集

  boosting算法由于重在于**降低偏差**，因而它对基训练器要求尽可能是方差减少，因而树的深度为8就能表现的很好，相对bagging有时需要20及以上。

- XGBOOST 比 RF 更适合做 feature importance？
  When the dataset has two (or more) **correlated features**, then from the point of view of the model, any of these correlated features can be used as the predictor, with no concrete preference of one over the others. But once one of them is used, the importance of others is significantly reduced since effectively the impurity they can remove is already removed by the first feature. As a consequence, they will have a lower reported importance. This is not an issue when we want to use feature selection to reduce overfitting, since it makes sense to remove features that are mostly duplicated by other features. But when interpreting the data, it can lead to the incorrect conclusion that one of the variables is a strong predictor while the others in the same group are unimportant, while actually they are very close in terms of their relationship with the response variable.

  Scores for X0, X1, X2: [0.278, 0.66, 0.062]

  When we compute the feature importances, we see that X1 is computed to have over 10x higher importance than X2, while their “true” importance is very similar.

---
- xgboost如何计算最终的feature importance?
  属性重要性是通过对数据集中的每个属性进行计算，并进行排序得到。在单个决策书中通过每个feature分裂点改进性能度量（Gain）的量来计算属性重要性，由节点负责加权和记录次数。也就说一个属性对分裂点改进性能度量越大（越靠近根节点），权值越大；被越多提升树所选择，属性越重要。性能度量可以是选择分裂节点的Gini纯度，也可以是其他度量函数。

  通常importance_type有3种options：
  - 性能度量gain：所有树的平均分
  - 加权weight: 该特征在所有树中被选中出现的次数（default）
  - 次数cover：在树中的平均覆盖率

  最终将一个属性在所有提升树中的结果进行加权求和后然后平均，得到重要性得分。

---
- 随机森林如何求variable importance？（类似gradient boosting）
  随机森林实际上是一种特殊的bagging方法，它将决策树用作bagging中的模型。首先，用bootstrap方法生成m个训练集，然后，对于每个训练集，构造一颗决策树，在节点找特征进行分裂的时候，并不是对所有特征找到能使得指标（如信息增益）最大的，而是在特征中随机抽取一部分特征，在抽到的特征中间找到最优解，应用于节点，进行分裂。随机森林的方法由于有了bagging，也就是集成的思想在，实际上相当于对于样本和特征都进行了采样（如果把训练数据看成矩阵，就像实际中常见的那样，那么就是一个行和列都进行采样的过程），所以可以避免过拟合。
  mean decrease impurity and mean decrease accuracy 

---
- 各集成树如何处理缺失值？
  xgboost把缺失值当做稀疏矩阵来对待，本身的在节点分裂时不考虑的缺失值的数值。缺失值数据会被分到左子树和右子树分别计层损失，选择gain measure较优的那一个。如果训练中没有数据缺失，预测时出现了数据缺失，那么默认被分类到右子树。

---
- xgboost的原理

  xgboost本身还是基于gradient boosting，下一棵树是基于上一棵树迭代而成，他的特色主要是并行、结点分裂、正则和二阶导。对于传统目标函数它添加了正则项，再利用泰勒二阶展开，增加了正则项，树越复杂，惩罚越大，这防止了over-fitting，而本身GradientBoosting并没有惩罚项；
  在迭代更新的时候，Xgboost采用了二阶导数（海瑟矩阵），而GradientBoosting只是用了一阶导数（梯度）；节点分裂的方式不同，gbdt是用的gini系数，xgboost是经过优化推导后的，树节点在进行分裂时，我们需要计算每个特征的每个分割点对应的增益，即用贪心法枚举所有可能的分割点。当数据无法一次载入内存或者在分布式情况下，贪心算法效率就会变得很低，所以xgboost还提出了一种可并行的近似直方图算法，用于高效地生成候选的分割点；此外，xgboost跑起来也更快，因为采用了并行计算、块处理、稀疏矩阵处理技术等等。

  - 支持线性分类器
  - 目标函数由损失函数和**正则**项组成 training loss + complexity of model，正则项由**叶子节点数量与叶子节点得分的l2模平方（对leaf score做了平滑防止过拟合）**
    - ![1547620209676](/assets/images/2019-01-15/1547620209676.png)
    - xg在每次学完一棵树，会在这棵树的叶子节点乘上一个eta**衰减系数**，来使后面的树有更大的学习空间，在优化目标函数的同时相当于做了预剪枝
    - 正则系数用来控制模型的**复杂度**
  - **列抽样**，类似随机森林
  - gbdt在损失函数只用了一阶信息，xg用了**两阶**
  - 自动学习缺失值的**分裂**方向
  - 并行计算**特征增益**
    - gbdt是用的gini系数，xgboost是经过优化推导后的
    - 这个并行化是特征粒度上的并行化：划分节点时，每个特征并行计算，同时每个特征的**划分节点也是并行计算**（这是加速最猛的处理）；XGBOOST只接受**连续变量**，划分特征提出了block的概念，简单的说**将排序后的特征值放在block中**，以后划分特征的时候，只需要遍历一次即可，因为决策树在处理属性值时，需要将属性值先排序，这是最耗时的步骤，而block预先存储了排序的特征值，在后续过程中可以重复利用这个结构中的数据，同时，计算每个特征的划分增益可以并行处理了Collecting statistics for each column can be parallelized,giving us a parallel algorithm for split finding!!；贪心算法在选择最佳划分方式时需要遍历所有的划分点子集，在数据非常大时，这会非常低效，xgboost提出了近似直方图计算，根据数据的二阶导信息进行排序，提出一些候选划分点子集
    - 利用并行近似直方图连续变量生成候选分割点（中位线）
    - 由节点负责加权和记录次数
    - ![1547620388263](/assets/images/2019-01-15/1547620388263.png)





### 其他
- 给你一个有1000列和1百万行的训练数据集。这个数据集是基于分类问题的。经理要求你来降低该数据集的维度以减少模型计算时间。你的机器内存有限。你会怎么做？（你可以自由做各种实际操作假设。)

  答：你的面试官应该非常了解很难在有限的内存上处理高维的数据。以下是你可以使用的处理方法：

1. 由于我们的RAM很小，首先要关闭机器上正在运行的其他程序，包括网页浏览器，以确保大部分内存可以使用。
2. 我们可以随机采样数据集。这意味着，我们可以创建一个较小的数据集，比如有1000个变量和30万行，然后做计算。
3. 为了降低维度，我们可以把数值变量和分类变量分开，同时删掉相关联的变量。对于数值变量，我们将使用相关性分析。对于分类变量，我们可以用卡方检验。
4. 另外，我们还可以使用PCA（主成分分析），并挑选可以解释在数据集中有最大偏差的成分。
5. 利用在线学习算法，如VowpalWabbit（在Python中可用）是一个可能的选择。
6. 利用Stochastic GradientDescent（随机梯度下降）法建立线性模型也很有帮助。
7. 我们也可以用我们对业务的理解来估计各预测变量对响应变量的影响大小。但是，这是一个主观的方法，如果没有找出有用的预测变量可能会导致信息的显著丢失。

  注意：对于第4和第5点，请务必阅读有关在线学习算法和随机梯度下降法的内容。这些是高阶方法。

- 在PCA中有必要做旋转变换吗？如果有必要，为什么？如果你没有旋转变换那些成分，会发生什么情况？

  答：是的，旋转（正交）是必要的，因为它把由主成分捕获的方差之间的差异最大化。这使得主成分更容易解释。但是不要忘记我们做PCA的目的是选择更少的主成分（与特征变量个数相较而言），那些选上的主成分能够解释数据集中最大方差。通过做旋转，各主成分的相对位置不发生变化，它只能改变点的实际坐标。如果我们没有旋转主成分，PCA的效果会减弱，那样我们会不得不选择更多个主成分来解释数据集里的方差。

  注意：对PCA（主成分分析）需要了解更多。

---
- 给你一个数据集。这个数据集有缺失值，且这些缺失值分布在离中值有1个标准偏差的范围内。百分之多少的数据不会受到影响？为什么？

  答：这个问题给了你足够的提示来开始思考！由于数据分布在中位数附近，让我们先假设这是一个正态分布。我们知道，在一个正态分布中，约有68％的数据位于跟平均数（或众数、中位数）1个标准差范围内的，那样剩下的约32%的数据是不受影响的。因此，约有32%的数据将不受到缺失值的影响。

---
- 给你一个癌症检测的数据集。你已经建好了分类模型，取得了96％的精度。为什么你还是不满意你的模型性能？你可以做些什么呢？

  答：如果你分析过足够多的数据集，你应该可以判断出来癌症检测结果是不平衡数据。在不平衡数据集中，精度不应该被用来作为衡量模型的标准，因为96％（按给定的）可能只有正确预测多数分类，但我们感兴趣是那些少数分类（4％），是那些被诊断出癌症的人。因此，为了评价模型的性能，应该用灵敏度（真阳性率），特异性（真阴性率），F值用来确定这个分类器的“聪明”程度。如果在那4%的数据上表现不好，我们可以采取以下步骤：

1. 我们可以使用欠采样、过采样或SMOTE让数据平衡。

  - 一种过采样算法SMOTE。概括来说，本算法基于“插值”来为少数类合成新的样本。![1547620425641](/assets/images/2019-01-15/1547620425641.png)

2. 我们可以通过概率验证和利用AUC-ROC曲线找到最佳阀值来调整预测阀值。
3. 我们可以给分类分配权重，那样较少的分类获得较大的权重。
4. 我们还可以使用异常检测。

  注意：要更多地了解不平衡分类

---
- 为什么朴素贝叶斯如此“朴素”？

  答：朴素贝叶斯太‘朴素’了，因为它假定所有的特征在数据集中的作用是同样重要和独立的。正如我们所知，这个假设在现实世界中是很不真实的。

---
- 解释朴素贝叶斯算法里面的先验概率、似然估计和边际似然估计？

  答：先验概率就是因变量（二分法）在数据集中的比例。这是在你没有任何进一步的信息的时候，是对分类能做出的最接近的猜测。例如，在一个数据集中，因变量是二进制的（1和0）。例如，1（垃圾邮件）的比例为70％和0（非垃圾邮件）的为30％。因此，我们可以估算出任何新的电子邮件有70％的概率被归类为垃圾邮件。似然估计是在其他一些变量的给定的情况下，一个观测值被分类为1的概率。例如，“FREE”这个词在以前的垃圾邮件使用的概率就是似然估计。边际似然估计就是，“FREE”这个词在任何消息中使用的概率。

---
- 你正在一个时间序列数据集上工作。经理要求你建立一个高精度的模型。你开始用决策树算法，因为你知道它在所有类型数据上的表现都不错。后来，你尝试了时间序列回归模型，并得到了比决策树模型更高的精度。这种情况会发生吗？为什么？

  答：众所周知，时间序列数据有线性关系。另一方面，决策树算法是已知的检测非线性交互最好的算法。为什么决策树没能提供好的预测的原因是它不能像回归模型一样做到对线性关系的那么好的映射。因此，我们知道了如果我们有一个满足线性假设的数据集，一个线性回归模型能提供强大的预测。

---
- 给你分配了一个新的项目，是关于帮助食品配送公司节省更多的钱。问题是，公司的送餐队伍没办法准时送餐。结果就是他们的客户很不高兴。最后为了使客户高兴，他们只好以免餐费了事。哪个机器学习算法能拯救他们？

  答：你的大脑里可能已经开始闪现各种机器学习的算法。但是等等！这样的提问方式只是来测试你的机器学习基础。这不是一个机器学习的问题，而是一个路径优化问题。机器学习问题由三样东西组成：

1. 模式已经存在。
2. 不能用数学方法解决（指数方程都不行）。
3. 有相关的数据。

  通过判断以上三个因素来决定机器学习是不是个用来解决特定问题的工具。

---
- 你意识到你的模型受到低偏差和高方差问题的困扰。应该使用哪种算法来解决问题呢？为什么？

  答：低偏差意味着模型的预测值接近实际值。换句话说，该模型有足够的灵活性，以模仿训练数据的分布。貌似很好，但是别忘了，一个灵活的模型没有泛化能力。这意味着，当这个模型用在对一个未曾见过的数据集进行测试的时候，它会令人很失望。在这种情况下，我们可以使用bagging算法（如随机森林），以解决高方差问题。bagging算法把数据集分成重复随机取样形成的子集。然后，这些样本利用单个学习算法生成一组模型。接着，利用投票（分类）或平均（回归）把模型预测结合在一起。另外，为了应对大方差，我们可以：

1. 使用正则化技术，惩罚更高的模型系数，从而降低了模型的复杂性。
2. 使用可变重要性图表中的前n个特征。可以用于当一个算法在数据集中的所有变量里很难寻找到有意义信号的时候。

---
- 给你一个数据集。该数据集包含很多变量，你知道其中一些是高度相关的。经理要求你用PCA。你会先去掉相关的变量吗？为什么？

  答：你可能会说不，但是这有可能是不对的。丢弃相关变量会对PCA有实质性的影响，因为有相关变量的存在，由特定成分解释的方差被放大。例如：在一个数据集有3个变量，其中有2个是相关的。如果在该数据集上用PCA，第一主成分的方差会是与其不相关变量的差异的两倍。此外，加入相关的变量使PCA错误地提高那些变量的重要性，这是有误导性的。

---
- 花了几个小时后，现在你急于建一个高精度的模型。结果，你建了5 个GBM （Gradient Boosted Models），想着boosting算法会显示魔力。不幸的是，没有一个模型比基准模型表现得更好。最后，你决定将这些模型结合到一起。尽管众所周知，结合模型通常精度高，但你就很不幸运。你到底错在哪里？**

  答：据我们所知，组合的学习模型是基于合并弱的学习模型来创造一个强大的学习模型的想法。但是，只有当各模型之间没有相关性的时候组合起来后才比较强大。由于我们已经试了5个 GBM，但没有提高精度，表明这些模型是相关的。具有相关性的模型的问题是，所有的模型提供相同的信息。例如：如果模型1把User1122归类为 1，模型2和模型3很有可能会做有同样分类，即使它的实际值应该是0，因此，只有弱相关的模型结合起来才会表现更好。

- KNN和KMEANS聚类（kmeans clustering）有什么不同？

  答：不要被它们的名字里的“K”误导。你应该知道，这两种算法之间的根本区别是，KMEANS本质上是无监督学习而KNN是监督学习。KMEANS是聚类算法。KNN是分类（或回归）算法。 KMEAN算法把一个数据集分割成簇，使得形成的簇是同构的，每个簇里的点相互靠近。该算法试图维持这些簇之间有足够的可分离性。由于无监督的性质，这些簇没有任何标签。NN算法尝试基于其k（可以是任何数目）个周围邻居来对未标记的观察进行分类。它也被称为懒惰学习法，因为它涉及最小的模型训练。因此，它不用训练数据对未看见的数据集进行泛化。

---
- 真阳性率和召回有什么关系？写出方程式。

  答：真阳性率=召回。是的，它们有相同的公式（TP / TP + FN）。

  注意：要了解更多关于估值矩阵的知识。

- 你建了一个多元回归模型。你的模型R2为并不如你设想的好。为了改进，你去掉截距项，模型R的平方从0.3变为0.8。这是否可能？怎样才能达到这个结果？

  答：是的，这有可能。我们需要了解截距项在回归模型里的意义。截距项显示模型预测没有任何自变量，比如平均预测。公式R² = 1 – ∑(y – y´)²/∑(y – ymean)²中的y´是预测值。 当有截距项时，R²值评估的是你的模型基于均值模型的表现。在没有截距项（ymean）时，当分母很大时，该模型就没有这样的估值效果了，∑(y – y´)²/∑(y – ymean)²式的值会变得比实际的小，而R2会比实际值大。

---
- 在分析了你的模型后，经理告诉你，你的模型有多重共线性。你会如何验证他说的是真的？在不丢失任何信息的情况下，你还能建立一个更好的模型吗？

  答：要检查多重共线性，我们可以创建一个相关矩阵，用以识别和除去那些具有75％以上相关性（决定阈值是主观的）的变量。此外，我们可以计算VIF（方差膨胀因子）来检查多重共线性的存在。 VIF值<= 4表明没有多重共线性，而值> = 10意味着严重的多重共线性。此外，我们还可以用容差作为多重共线性的指标。但是，删除相关的变量可能会导致信息的丢失。为了留住这些变量，我们可以使用惩罚回归模型，如Ridge和Lasso回归。我们还可以在相关变量里添加一些随机噪声，使得变量变得彼此不同。但是，增加噪音可能会影响预测的准确度，因此应谨慎使用这种方法。

  注意：多了解关于回归的知识。

---
- 什么时候Ridge回归优于Lasso回归？

  答：你可以引用ISLR的作者Hastie和Tibshirani的话，他们断言在对少量变量有中等或大尺度的影响的时候用lasso回归。在对多个变量只有小或中等尺度影响的时候，使用Ridge回归。

  从概念上讲，我们可以说，Lasso回归（L1）同时做**变量选择和参数收缩**，而ridge回归只做**参数收缩**，并最终在模型中包含所有的系数。在有相关变量时，ridge回归可能是首选。此外，ridge回归在用最小二乘估计有更高的偏差的情况下效果最好。因此，选择合适的模型取决于我们的模型的目标。

  注意：多了解关于ridge和lasso回归的相关知识。

---
- 全球平均温度的上升导致世界各地的海盗数量减少。这是否意味着海盗的数量减少引起气候变化？

  答：看完这个问题后，你应该知道这是一个“因果关系和相关性”的经典案例。我们不能断定海盗的数量减少是引起气候变化的原因，因为可能有其他因素（潜伏或混杂因素）影响了这一现象。全球平均温度和海盗数量之间有可能有相关性，但基于这些信息，我们不能说因为全球平均气温的上升而导致了海盗的消失。

  注意：多了解关于因果关系和相关性的知识。

---
- 如何在一个数据集上选择重要的变量？给出解释。

  答：以下是你可以使用的选择变量的方法：

1. 选择重要的变量之前除去相关变量
2. 用线性回归然后基于P值选择变量
3. 使用前向选择，后向选择，逐步选择
4. 使用随机森林和Xgboost，然后画出变量重要性图
5. 使用lasso回归
6. 测量可用的特征集的的信息增益，并相应地选择前n个特征量。
7. PCA/SVD

---
- 协方差和相关性有什么区别？

  答：相关性是协方差的标准化格式。协方差本身很难做比较。例如：如果我们计算工资（$）和年龄（岁）的协方差，因为这两个变量有不同的度量，所以我们会得到不能做比较的不同的协方差。为了解决这个问题，我们计算相关性来得到一个介于-1和1之间的值，就可以忽略它们各自不同的度量。

---
- 是否有可能捕获连续变量和分类变量之间的相关性？如果可以的话，怎样做？

  答：是的，我们可以用ANCOVA（协方差分析）技术来捕获连续型变量和分类变量之间的相关性。


- 运行二元分类树算法很容易，但是你知道一个树是如何做分割的吗，即树如何决定把哪些变量分到哪个根节点和后续节点上？

  答：分类树利用基尼系数与节点熵来做决定。简而言之，树算法找到最好的可能特征，它可以将数据集分成最纯的可能子节点。树算法找到可以把数据集分成最纯净的可能的子节点的特征量。基尼系数是，如果总体是完全纯的，那么我们从总体中随机选择2个样本，而这2个样本肯定是同一类的而且它们是同类的概率也是1。我们可以用以下方法计算基尼系数：

1. 利用成功和失败的概率的平方和(p^2+q^2)计算子节点的基尼系数
2. 利用该分割的节点的加权基尼分数计算基尼系数以分割

  熵是衡量信息不纯的一个标准（二分类）：

  这里的p和q是分别在该节点成功和失败的概率。当一个节点是均匀时熵为零。当2个类同时以50%对50%的概率出现在同一个节点上的时候，它是最大值。熵越低越好。

---
- 你已经建了一个有10000棵树的随机森林模型。在得到0.00的训练误差后，你非常高兴。但是，验证错误是34.23。到底是怎么回事？你还没有训练好你的模型吗？

  答：该模型过度拟合。训练误差为0.00意味着分类器已在一定程度上模拟了训练数据，这样的分类器是不能用在未看见的数据上的。因此，当该分类器用于未看见的样本上时，由于找不到已有的模式，就会返回的预测有很高的错误率。在随机森林算法中，用了多于需求个数的树时，这种情况会发生。因此，为了避免这些情况，我们要用交叉验证来调整树的数量。

---

- 你有一个数据集，变量个数p大于观察值个数n。为什么用OLS是一个不好的选择？用什么技术最好？为什么？

  答：在这样的高维数据集中，我们不能用传统的回归技术，因为它们的假设往往不成立。当p>nN，我们不能计算唯一的最小二乘法系数估计，方差变成无穷大，因此OLS无法在此使用的。为了应对这种情况，我们可以使用惩罚回归方法，如lasso、LARS、ridge，这些可以缩小系数以减少方差。准确地说，当最小二乘估计具有较高方差的时候，ridge回归最有效。

  其他方法还包括子集回归、前向逐步回归。

---
- 什么是凸包？（提示：想一想SVM）

  答：当数据是线性可分的，凸包就表示两个组数据点的外边界。一旦凸包建立，我们得到的最大间隔超平面（MMH）作为两个凸包之间的垂直平分线。 MMH是能够最大限度地分开两个组的线。

---
- 我们知道，一位有效编码会增加数据集的维度。但是，标签编码不会。为什么？

  答：对于这个问题不要太纠结。这只是在问这两者之间的区别。
  用一位有效编码编码，数据集的维度（也即特征）增加是因为它为分类变量中存在的的每一级都创建了一个变量。例如：假设我们有一个变量“颜色”。这变量有3个层级，即红色、蓝色和绿色。对“颜色”变量进行一位有效编码会生成含0和1值的Color.Red，Color.Blue和Color.Green 三个新变量。在标签编码中，分类变量的层级编码为0和1，因此不生成新变量。标签编码主要是用于二进制变量。

---
- 你会在时间序列数据集上使用什么交叉验证技术？是用k倍或LOOCV？

  答：都不是。对于时间序列问题，k倍可能会很麻烦，因为第4年或第5年的一些模式有可能跟第3年的不同，而对数据集的重复采样会将分离这些趋势，我们可能最终是对过去几年的验证，这就不对了。相反，我们可以采用如下所示的5倍正向链接策略：

  fold 1 : training [1], test [2]
  fold 2 : training [1 2], test [3]
  fold 3 : training [1 2 3], test [4]
  fold 4 : training [1 2 3 4], test [5]
  fold 5 : training [1 2 3 4 5], test [6]

  1，2，3，4，5，6代表的是年份。

---
- 给你一个缺失值多于30%的数据集？比方说，在50个变量中，有8个变量的缺失值都多于30%。你对此如何处理？

  答：我们可以用下面的方法来处理：

1. 把缺失值分成单独的一类，这些缺失值说不定会包含一些趋势信息。
2. 我们可以毫无顾忌地删除它们。
3. 或者，我们可以用目标变量来检查它们的分布，如果发现任何模式，我们将保留那些缺失值并给它们一个新的分类，同时删除其他缺失值。

---
- “买了这个的客户，也买了......”亚马逊的建议是哪种算法的结果？

  答：这种推荐引擎的基本想法来自于协同过滤。
  协同过滤算法考虑用于推荐项目的“用户行为”。它们利用的是其他用户的购买行为和针对商品的交易历史记录、评分、选择和购买信息。针对商品的其他用户的行为和偏好用来推荐项目（商品）给新用户。在这种情况下，项目（商品）的特征是未知的。

  注意：了解更多关于推荐系统的知识。

---
- 你怎么理解第一类和第二类错误？

  答：第一类错误是当原假设为真时，我们却拒绝了它，也被称为“假阳性”。第二类错误是当原假设为是假时，我们接受了它，也被称为“假阴性”。在混淆矩阵里，我们可以说，当我们把一个值归为阳性（1）但其实它是阴性（0）时，发生第一类错误。而当我们把一个值归为阴性（0）但其实它是阳性（1）时，发生了第二类错误。

---
- 当你在解决一个分类问题时，出于验证的目的，你已经将训练集随机抽样地分成训练集和验证集。你对你的模型能在未看见的数据上有好的表现非常有信心，因为你的验证精度高。但是，在得到很差的精度后，你大失所望。什么地方出了错？

  答：在做分类问题时，我们应该使用分层抽样而不是随机抽样。随机抽样不考虑目标类别的比例。相反，分层抽样有助于保持目标变量在所得分布样本中的分布。

---
- 你被要求基于R²、校正后的R²和容差对一个回归模型做评估。你的标准会是什么？

  答：容差（1 / VIF）是多重共线性的指标。它是一个预测变量中的方差的百分比指标，这个预测变量不能由其他预测变量来计算。容差值越大越好。相对于R²我们会用校正R²，因为只要增加变量数量，不管预测精度是否提高，R²都会变大。但是，如果有一个附加变量提高了模型的精度，则校正R²会变大，否则保持不变。很难给校正R²一个标准阈值，因为不同数据集会不同。例如：一个基因突变数据集可能会得到一个较低的校正R²但仍提供了相当不错的预测，但相较于股票市场，较低的校正R²只能说明模型不好。

---
- 在k-means或kNN，我们是用欧氏距离来计算最近的邻居之间的距离。为什么不用曼哈顿距离？

  答：**我们不用曼哈顿距离，因为它只计算水平或垂直距离，有维度的限制。另一方面，欧式距离可用于任何空间的距离计算问题**。因为，数据点可以存在于任何空间，欧氏距离是更可行的选择。例如：想象一下国际象棋棋盘，象或车所做的移动是由曼哈顿距离计算的，因为它们是在各自的水平和垂直方向的运动。

---
- 把我当成一个5岁的小孩来解释机器学习。

  答：很简单。机器学习就像婴儿学走路。每次他们摔倒，他们就学到（无知觉地）并且明白，他们的腿要伸直，而不能弯着。他们下一次再跌倒，摔疼了，摔哭了。但是，他们学会“不要用那种姿势站着”。为了避免摔疼，他们更加努力尝试。为了站稳，他们还扶着门或墙壁或者任何靠近他们的东西。这同样也是一个机器如何在环境中学习和发展它的“直觉”的。

  注意：这个面试问题只是想考查你是否有深入浅出地讲解复杂概念的能力。

---
- 我知道校正R²或者F值来是用来评估线性回归模型的。那用什么来评估逻辑回归模型？

  答：我们可以使用下面的方法：

1. 由于逻辑回归是用来预测概率的，我们可以用AUC-ROC曲线以及混淆矩阵来确定其性能。
2. 此外，在逻辑回归中类似于校正R²的指标是AIC。AIC是对模型系数数量惩罚模型的拟合度量。因此，我们更偏爱有最小AIC的模型。
3. 空偏差指的是只有截距项的模型预测的响应。数值越低，模型越好。残余偏差表示由添加自变量的模型预测的响应。数值越低，模型越好。

---
- 考虑到机器学习有这么多算法，给定一个数据集，你如何决定使用哪一个算法？

  答：你应该说，机器学习算法的选择完全取决于数据的类型。如果给定的一个数据集是线性的，线性回归是最好的选择。如果数据是图像或者音频，那么神经网络可以构建一个稳健的模型。如果该数据是非线性互相作用的的，可以用boosting或bagging算法。如果业务需求是要构建一个可以部署的模型，我们可以用回归或决策树模型（容易解释和说明），而不是黑盒算法如SVM，GBM等。总之，没有一个一劳永逸的算法。我们必须有足够的细心，去了解到底要用哪个算法。

---
- 你认为把分类变量当成连续型变量会更得到一个更好的预测模型吗？

  回答：为了得到更好的预测，只有在分类变量在本质上是有序的情况下才可以被当做连续型变量来处理。

---
- 什么时候正则化在机器学习中是有必要的？

  答：当模型过度拟合或者欠拟合的时候，正则化是有必要的。这个技术引入了一个成本项，用于带来目标函数的更多特征。因此，正则化是将许多变量的系数推向零，由此而降低成本项。这有助于降低模型的复杂度，使该模型可以在预测上（泛化）变得更好。

---
- 你是怎么理解偏差方差的平衡？

  答：从数学的角度来看，任何模型出现的误差可以分为三个部分。以下是这三个部分：

  偏差误差在量化平均水平之上预测值跟实际值相差多远时有用。高偏差误差意味着我们的模型表现不太好，因为没有抓到重要的趋势。而另一方面，方差量化了在同一个观察上进行的预测是如何彼此不同的。高方差模型会过度拟合你的训练集，而在训练集以外的数据上表现很差。

---
- OLS是用于线性回归。最大似然是用于逻辑回归。解释以上描述。

  答：OLS和最大似然是使用各自的回归方法来逼近未知参数（系数）值的方法。简单地说，普通最小二乘法（OLS）是线性回归中使用的方法，它是在实际值和预测值相差最小的情况下而得到这个参数的估计。最大似然性有助于选择使参数最可能产生观测数据的可能性最大化的参数值。

---
- What R packages are commonly used?
  RMysql/RIDBC/readr/data.table for reading data and database connection;
  dplyr/stringr/lubridate for data, string, date manapulation;
  caret/xgboost for machine learning, leverage several different algorithmns and automatically parallizes task;
  ggplot2/shinyr/rcolorbrewer for data visualization;

---
- Why model ensembling reduces error rate and why it works better to ensemble low-correlated model predictions？
  模型融合针是一种非常有效的技术，它可以明显提升ML任务的表现成绩。通过把多个单模型融合在一起，能够降低bias，variance，控制Overfitting，提高准确率。几何上来说，把多个崎岖的分类线平均会有助于接近真实的平滑分割线。

---
- Please introduce highly used algorithmns.
  LR: 面对一个回归或者分类问题，建立代价函数，然后通过优化方法迭代求解出最优的模型参数，然后测试验证我们这个求解的模型的好坏。

  SVM: SVM的核心思想是尽最大努力使分开的两个类别有最大间隔，这样才使得分隔具有更高的可信度。而且对于未知的新样本才有很好的分类预测能力（在机器学习中叫泛化能力）
  那么怎么描述这个间隔，并且让它最大呢？SVM的办法是：让离分隔面最近的数据点具有最大的距离。

  RF: 通过自助法（bootstrap）重采样技术，从原始训练样本集N中有放回地重复随机抽取k个样本生成新的训练样本集合，然后根据自助样本集生成k个分类树组成随机森林，新数据的分类结果按分类树投票多少形成的分数而定。其实质是对决策树算法的一种改进，将多个决策树合并在一起，每棵树的建立依赖于一个独立抽取的样品，森林中的每棵树具有相同的分布，分类误差取决于每一棵树的分类能力和它们之间的相关性。特征选择采用随机的方法去分裂每一个节点，然后比较不同情况下产生的误差。能够检测到的内在估计误差、分类能力和相关性决定选择特征的数目。单棵树的分类能力可能很小，但在随机产生大量的决策树后，一个测试样品可以通过每一棵树的分类结果经统计后选择最可能的分类。

  那么，“随机”是干啥的？随机森林的随机有两层意思。
  训练样本选取随机。虽然每一棵树的训练样本个数都是样本总数N，但是每一个样本的随机选取都是有放回的选取。这样，每一颗树的训练样本几乎都不相同。
  特征选取随机。假设训练数据有M个特征，随机森林的每一颗树的每一次branch只选取m（m< M）个特征用于构建决策树。每一颗树选取的特征可能都不完全相同。
  强调：随机森林不进行剪枝。决策树剪枝是因为防止过拟合，而随机森林的“随机”已经防止了过拟合，因此不需要剪枝。可以这样比喻随机森林算法：每一棵决策树就是一个精通于某一个窄领域 的专家（因为我们从M个feature中选择m让每一棵决策树进行学习），这样在随机森林中就有了很多个精通不同领域的专家，对一个新的问题（新的输入数 据），可以用不同的角度去看待它，最终由各个专家，投票得到结果。
  补充：随机森林有2个参数需要人为控制，一个是森林中树的数量，一般建议取很大。另一个是m的大小，推荐m的值为M的均方根。
  最后说一下随机森林的优缺点：
  不用做特征选择
  在训练完后，它能够给出哪些feature比较重要

  AdaBoost: 提高那些被前一轮弱分类器错误分类样本的权值，而降低那些被正确分类样本的权值。

  加权多数表决的方法，加大分类误差率小的弱分类器的权值，使其在表决中起较大作用，减小分类误差率大的弱分类器的权值，使其在表决中起较小的作用。


- 什么样的模型对缺失值更敏感?
  - 树模型对缺失值的敏感度低，大部分时候可以在数据缺失时时使用。
  - 涉及到距离度量(distancemeasurement)时，如计算两个点之间的距离，缺失数据就变得比较重要。因为涉及到"距离离"这个概念，那么缺失值处理不当就会导致效果很差，如K近邻算法（KNN）、支持向量机(SVM)。
  - 线性模型的代价函数(loss function)往往涉及到距离(distance)的计算，计罰筛则值和真实值之间的差别，这容易导致对缺失值敏感。
  - 神经网络的鲁棒强，对于缺失数据不是非常敏感，但一|g没有那么多数据可供使用。
  - 贝叶斯模型对于缺失数据也比较稳定，数据量很小的时候雜贝叶斯模型。
  - 总体来看，对于有缺失值的数据在经过缺失处理后：
    - 数据量很小，朴素贝叶斯
    - 数据量适中或者较大，用树横型，优先xgboost
    - 数据量较大，也可以用神经网络
    - 避免使用距离度量相关的模型，如KNN和SVM

---
- 多种损失函数的差异？
  - square loss (回归)
  - hinge loss (SVM)
  - logistic loss 
  - cross entropy loss(log loss、softmax loss) （分类、nn）
  - exponential loss （集成算法）
  - 0-1 loss
  - 绝对值损失

https://blog.csdn.net/u010976453/article/details/78488279





## 深度学习
### CV
#### 神经网络backprop
![1547620532435](/assets/images/2019-01-15/1547620532435.png)
![1547620561027](/assets/images/2019-01-15/1547620561027.png)
https://www.cnblogs.com/charlotte77/p/5629865.html

feature_map_size = ((image_size+2*pad-filter_size)/stride)+1

#### CNN, RCNN, fast-RCNN,faster-RCNN
- [CNN与RNN]![Alt text](./1546177362693.png)
- [RNN几种variants对比]![Alt text](./1546176414973.png)![Alt text](./1546176375120.png)

#### 目标检测两大类
![Alt text](./1545625394829.png)
- two-stage: region proposal binary classification(background or not) -> object classifier
- one-stage: object classifier

#### R-CNN（region）
![Alt text](./1545632648993.png)
- selective search for region proposals，cnn for features，svm for classification
  - Run Selective Search to generate ~1000 probable objects (ROI) (where the object is more likely to be found): wrap image size for CNN
  - Feed these patches to CNN, followed by SVM to predict the class of each patch.
  - Optimize patches by training bounding box regression separately.

Still, RCNN was very slow. Because running CNN on **2000 region proposals** generated by Selective search takes a lot of time. 

#### SPP-net
With SPP-net, we calculate the CNN representation for **entire image only once** and can use that to calculate the CNN representation for each patch generated by Selective Search.

#### Fast R-CNN
![Alt text](./1545632690089.png)
- entire image
- RoIs (region of interests) and wrap image region
- CNN
- classification and bbox coordinates
#### Faster R-CNN
![Alt text](./1545632818404.png)
- entire image
- CNN and region proposal network
- project region proposals to conv feature map
- classification and bbox coordinates
#### Mask R-CNN
![Alt text](./1545632715562.png)
- entire image
- CNN and region proposal network
- project region proposals to conv feature map
- predict a mask
#### RetinaNet (one-stage)
- FPN + sub-network + FL
- loss function
  CE(p_t) = -log(p_t) -> FL(p_t) = -(1-p_t)^gamma * log(p_t)
  量少的类别更有话语权
#### YOLO
- train: resize 448*448 -> 7*7 grids (with each grid 64*64)
  each grid -> 2 bbox (bounding box) -> 2*4 cooridinates -> P(Object)*IOU^{truth}_{pred}）
  each grid -> 20 conditional class probability P(C_{i}|Object)
  so, we can get （7*7*(2*5+20)=1470 outputs）
- predict: P(C_{i}|Object)*P(Object)*IOU^{truth}_{pred}

#### SVM vs. softmax
![Alt text](./1546826684719.png)

#### ResNet和YOLO
##### ResNet
![Alt text](./1545888347118.png)
- ResNet的核心特色在于利用**skip-connection**的理念缓解**梯度消失**的问题，他不是传统意义上的一层层传入传出，而是允许原始输入信息直接传到后面的层种，使得这一层的神经网络可以不用学习整个的输出，而是学习上一个网络输出的残差，因此全称叫做residual network。
- ResNet使用了一个新的思想，ResNet的思想是假设我们涉及一个网络层，存在最优化的网络层次，那么往往我们设计的深层次网络是有很多网络层为冗余层的。那么我们希望这些**冗余层**能够完成**恒等映射identity**，保证经过该恒等层的输入和输出完全相同。
- 核心：ResNet的过人之处，是他很大程度上解决了当今深度网络头疼的**网络退化**问题和**梯度消失**问题。
  - 使用残差网络结构h(x)=F(x)+x代替原来的没有shortcut连接的h(x)=x,这样更新冗余层的参数时需要学习F(x)=0比学习h(x)=x要容易得多。
  - 而shortcut连接的结构也保证了反向传播更新参数求梯度时，很难有梯度为0的现象发生，不会导致梯度消失。

  > 网络的退化，举个例子，假设已经有了一个最优化的网络结构，是18层。当我们设计网络结构的时候，我们并不知道具体多少层次的网络时最优化的网络结构，假设设计了34层网络结构。那么多出来的16层其实是冗余的，我们希望训练网络的过程中，模型能够自己训练这五层为恒等映射，也就是经过这层时的输入与输出完全一样。但是往往模型很难将这16层恒等映射的参数学习正确，那么就一定会不比最优化的18层网络结构性能好，这就是随着网络深度增加，模型会产生退化现象。它不是由过拟合产生的，而是由冗余的网络层学习了不是恒等映射的参数造成的。

性质
- 如果将residual block的weights设为0，相当于就是一个恒等式identity，使得block可以不用去学习 他不需要学习的信息，给weights加了l2正则使得所有参数趋近于0，对于传统的nn不合理的事对于rnn就合理了
- 
> utilizing skip-connections technique to solve the problem of vanishing gradient for deep neutual network 
> A residual neural network is an artificial neural network (ANN) of a kind that builds on constructs known from pyramidal cells in the cerebral cortex[citation needed]. Residual neural networks do this by utilizing skip connections or short-cuts to jump over some layers. In its limit as ResNets it will only skip over a single layer.[1] With an additional weight matrix to learn the skip weights it is referred to as HighwayNets.[2] With several parallel skips it is referred to as DenseNets.[3] In comparison, a non-residual neural network is described as a plain network in the context of residual neural networks.

- skip-connection
- no FC layer
- use bottleneck to improve efficiency 
- randomly drop a subset of layers during training to reduce vanishing gradients and training time through short networks

案例
![Alt text](./1546482876336.png)

1.  (200, 301, 3)   根据原始图的最小边确定缩放比例，比如![Alt text](./1546500847518.png)
2.  -> (1, 11637, 84) 进行expand_dim(x,0)后归一化，![Alt text](./1546502346306.png)
    -> (11637,) - [0, 84] 预测的类别号（取第一个矩阵第4列之后每列值最大的行序，对应图片预测的类别）
    -> (11637,) - [0, 1] 不同类别的概率（取第一个矩阵最后一行对应第（4+预测类别号））
    ![1547620799001](/assets/images/2019-01-15/1547620799001.png)



##### YOLO
- 将输入图像分割成G×G的网格，对于每个网格单元，运行一个CNN网络，运行 **non-max suppression**（选择最大概率的边界框并将与其交并比50的边界框删除） 算法，删除任何可能的重复重叠边界框。
  ![Alt text](./1546504491715.png)

## NLP
### fastText，TextRNN，LR的区别
fasttext是Word2Vec的一种衍生，主要将输入从传统词衍生到n-gram词，通过固定位数的词的组合作为词嵌入向量（word embedding vector），之后用浅层nn进行训练。
> For instance, the tri-grams for the word apple is app, ppl, and ple (ignoring the starting and ending of boundaries of words). The word embedding vector for apple will be the sum of all these n-grams. After training the Neural Network, we will have word embeddings for all the n-grams given the training dataset. Rare words can now be properly represented since it is highly likely that some of their n-grams also appears in other words. I will show you how to use FastText with Gensim in the following section.
> 尽管TextCNN能够在很多任务里面能有不错的表现，但CNN有个最大问题是固定 filter_size 的视野，一方面无法建模更长的序列信息，另一方面 filter_size 的超参调节也很繁琐。CNN本质是做文本的特征表达工作，而自然语言处理中更常用的是递归神经网络（RNN, Recurrent Neural Network），能够更好的表达上下文信息。具体在文本分类任务中，Bi-directional RNN（实际使用的是双向LSTM）从某种意义上可以理解为可以捕获变长且双向的的 "n-gram" 信息。

- **fastText** 的本质是“暴力”地将一个句子的词向量加权求和，作为该句子的vector，然后根据这个vector，乘以权重，使用softmax分类。这可能是fastText的速度快的原因所在吧。当然，模型中也使用了hashing trick，hierarchical softmax等进行加速、内存优化。跟cbow很像，cbow根据context预测中心词，而fasttext根据“context”预测句子label。
- ![1547620689509](/assets/images/2019-01-15/1547620689509.png)
  - 输入层：fastText中的"context"与cbow中的定义不同，为了将word order考虑进来，fastext使用了N-gram feature，也就是下图中的 X_1, X_2,....,X_N。这些输入是n-gram向量，这些向量是随机生成的。参见斤木在word2vec是如何得到词向量的？
  - 隐层：输入层是如何到隐层的呢？对于cbow，简单的求和；对于fastText，隐层是由输入层求和并平均，乘以权重矩阵A得到的。
  - 输出层：由隐层乘以权重矩阵B得到的。
  - ![1547620721642](/assets/images/2019-01-15/1547620721642.png)
- **TextCNN** 文本输入x，先进行embedding，然后不同的卷积做feature mapping 并进行max_pooling操作，最后是全联接分类层。
  - 预训练词向量，情况A：将词向量分为2组，作为不同的channel，一组不fine-tuned，一组fine-tuned，效果较好，情况B：不分组，训练过程中词向量fine-tuned效果也不错；
  - 不同filter-size，提取不同的N-gram信息；
  - 单层卷积后，接max-pooling，提取对于任务的最关键信息，并且天然的，max-pooling后向量与句子长度无关，对于变长输入的处理变得简单；
  - 网络结构：cnn+max-pooling+dropout+fc（l2正则）+softmax。

![1547620749167](/assets/images/2019-01-15/1547620749167.png)

### NER

####  经典方法的演变过程

**RNN、LSTM**都是对时序数据进行序列处理，由于RNN对数据的传输没有进行太多约束，使得长期信息顺序传输中很容易遭遇梯度消失或是梯度爆炸的问题（当初始权重都接近于0，在长期乘积会很快趋于0，使得梯度消失），人们开发了LSTM，利用memory cell多个转换门的LSTM，类似于ResNet只保留或更新有意义的信息，通过tanh（应对梯度消失）和sigmoid（应对信息筛选）结合的进入门/遗忘门/输出门。但是LSTM 中仍然存在按顺序地从过去单元到当前单元的序列路径，衍生了Bi-LSTM。但是它们最多只能记住约 100s 的长期信息，而不是 1000s 或 10000s 等，非常消耗计算资源且递归不可并行，因此又衍生了能找到可向前预测和向后回顾的计算单元的注意力attention算法，它完全基于注意力机制，让架构自己判断哪些向量需要储存，而哪些不需要，彻底放弃了循环和卷积。

**LSTM**：像RNN、LSTM、BILSTM这些模型，它们在序列建模上很强大，它们能够capture长远的上下文信息，此外还具备神经网络拟合非线性的能力，这些都是crf无法超越的地方，对于t时刻来说，输出层y_t受到隐层h_t（包含上下文信息）和输入层x_t（当前的输入）的影响，但是y_t和其他时刻的y_t`是相互独立的，感觉像是一种point wise，对当前t时刻来说，我们希望找到一个概率最大的y_t，但其他时刻的y_t`对当前y_t没有影响，如果y_t之间存在较强的依赖关系的话（例如，形容词后面一般接名词，存在一定的约束），LSTM无法对这些约束进行建模，LSTM模型的性能将受到限制。

**CRF**：它不像LSTM等模型，能够考虑长远的上下文信息，它更多考虑的是整个句子的局部特征的线性加权组合（通过特征模版去扫描整个句子）。关键的一点是，CRF的模型为p(y | x, w)，注意这里y和x都是序列，它有点像list wise，优化的是一个序列y = (y1, y2, …, yn)，而不是某个时刻的y_t，即找到一个概率最高的序列y = (y1, y2, …, yn)使得p(y1, y2, …, yn| x, w)最高，它计算的是一种联合概率，优化的是整个序列（最终目标），而不是将每个时刻的最优拼接起来，在这一点上CRF要优于LSTM。

**HMM**：CRF不管是在实践还是理论上都要优于HMM，HMM模型的参数主要是“初始的状态分布”，“状态之间的概率转移矩阵”，“状态到观测的概率转移矩阵”，这些信息在CRF中都可以有，例如：在特征模版中考虑h(y1), f(y_i-1, y_i), g(y_i, x_i)等特征。

**CRF与LSTM**：从数据规模来说，在数据规模较小时，CRF的试验效果要略优于BILSTM，当数据规模较大时，BILSTM的效果应该会超过CRF。从场景来说，如果需要识别的任务不需要太依赖长久的信息，此时RNN等模型只会增加额外的复杂度，此时可以考虑类似科大讯飞FSMN（一种基于窗口考虑上下文信息的“前馈”网络）。CNN＋BILSTM＋CRF：这是目前学术界比较流行的做法，BILSTM＋CRF是为了结合以上两个模型的优点，

**CNN**主要是处理英文的情况，英文单词是由更细粒度的字母组成，这些字母潜藏着一些特征（例如：前缀后缀特征），通过CNN的卷积操作提取这些特征，在中文中可能并不适用（中文单字无法分解，除非是基于分词后），这里简单举一个例子，例如词性标注场景，单词football与basketball被标为名词的概率较高， 这里后缀ball就是类似这种特征。BILSTM+CRF的Tensorflow版本：https://github.com/chilynn/sequence-labeling，主要参考了GitHub - glample/tagger: Named Entity Recognition Tool的实现，tagger是基于theano实现的，每一轮的参数更新是基于一个样本的sgd，训练速度比较慢。sequence-labeling是基于tensorflow实现的，将sgd改成mini-batch sgd，由于batch中每个样本的长度不一，训练前需要padding，最后的loss是通过mask进行计算（根据每个样本的真实长度进行计算）。

#### 经典方法原理

- CRF
   -  判别式概率无向图模型 （discriminative undirected probabilistic graphical model）
     -  This variant of the CRF is factored into **unary potentials for every element** in the sequence and **binary potentials for every transition** between output tags.
       -  Compute unary scores from a linear layer. 
       -  Compute the log-likelihood of the gold sequences and keep the transition params for inference at test time.
       -  Compute the viterbi sequence and score.
       -  loss是-loglikelihood
       -  accuracy是评价指标
     -  neighbour information, sentence level
       - 随机场是由若干个位置组成的整体，当给每一个位置中按照某种分布随机赋予一个值之后，其全体就叫做随机场。还是举词性标注的例子：假如有一个十个词形成的句子需要做词性标注。这十个词每个词的词性可以在已知的词性集合（名词，动词...)中去选择。当我们为每个词选择完词性后，这就形成了一个随机场。
       - 马尔可夫是随机场的特例，只注重当前位置neighbour的位置对应的值
     -  ![enter image description here](https://img-blog.csdn.net/20171023150418721?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvRENYX2FiYw==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast)

   -  LSTM
     - RNN的衍生
       -  $s_t=f(Ux_t) + Ws_{t-1})$
       -  $s_t$ can be think of as the memory of the network
       -  RNN shares the same parameters (U,V,W) across all steps in order to reduce parameters
     - Long Short-Term Memory networks are the same as RNNs, except that the hidden layer updates are replaced by different function (by purpose-built memory cells) (long range dependencies)
     - enables the model to predict the current output conditioned on long distance features
     - **为什么 RNN 在实际中并不会成功？**在训练 RNN 的过程中，信息在循环中一次又一次的传递会导致神经网络模型的权重发生很大的更新。这是因为每次更新中的误差梯度都会积累起来，因此会导致一个不稳定的网络。在极端情况下，权值可能会变得过大以至于溢出并形成一个非数值（NaN)。网络层之间的梯度（值大于 1）重复相乘导致梯度爆炸，而小于 1 的梯度重复相乘会造成梯度消失。
       - **为什么使用 tanh？**为了克服梯度消失问题，我们需要一个二阶导数在到达 0 之前能够持续很长范围的函数。tanh 函数就是满足这一属性的合适函数。
       - **为什么使用 Sigmoid？**Sigmoid 可以输出 0 或 1，因此它可用来遗忘或者记住信息。
       - **LSTM的几重门各有什么作用？**
         - LSTM 具备一种特殊的结构，能够让网络忘记不必要的信息。Sigmoid 层以 X(t) 和 h(t-1) 为输入，并且决定旧输出的哪一部分应该被删除（通过输出 0）。在我们的例子中，当输入是「他有一位女性朋友 Maria」时，「David」的性别可以被忘记了，因为这里的主语已经变成「Maria」了。这个门被称作「遗忘门」f(t)。遗忘门的输出是 f(t)*c(t-1)。
         - 下一步就是利用 cell 状态的新输入 X(t) 做决策并存储信息。Sigmoid 层决定哪个新信息应该被更新或者被忽略。tanh 层从新输入中创建一个新向量，向量的值是所有可能的值。然后这两个值相乘来更新新的 cell 状态。然后这个新记忆和旧的记忆 c(t-1) 加起来得到 c(t)。在我们的例子中，对于新的输入「他有一位女性朋友 Maria」，Maria 的性别就会被更新。当输入是「Maria 在纽约一家著名餐厅当厨师，最近他在一次校友会上遇到了她」（Maria works as a cook in a famous restaurant in New York whom he met recently in a school alumni meet）时，像「famous」、「school alumni meet」这些词可以被忽略，而「cooking」、「restaurant」以及「New York」这样的词将被更新。
         - 最后，我们需要决定输出什么。sigmoid 层决定了我们要输出 cell 状态的哪一部分。然后，我们使 cell 状态通过 tanh 层来生成所有可能的值，并将它与 sigmoid 门的输出相乘，所以我们只输出想要输出的部分。在我们的例子中，我们想要预测空格中的单词，模型可以从记忆中得知它是一个与「cook」相关的词，因此它就可以很容易地回答这个词是「cooking」。我们的模型不是从瞬时依赖中学习这个答案，而是从长期依赖中学到的。
   -  Bi-LSTM（双向）			
     - RNN的一种，非常适用于时序序列数据如文本
     - 可以捕捉到较长距离的依赖关系，如“我不觉得他好”。“不”字是对后面“好”的否定，即该句子的情感极性是贬义
     - 可以编码从后到前的信息，这是LSTM不行的，如“这个餐厅脏得不行，没有隔壁好”，这里的“不行”是对“脏”的程度的一种修饰，通过BiLSTM可以更好的捕捉双向的语义依赖
     - ![enter image description here](https://image.jiqizhixin.com/uploads/editor/37a1ae9e-9e95-44e5-8746-e03085f7e7f8/1540354951193.png)

   -  BiLSTM-CRF
     - can use both past and future input features and sentence level tag information
     - less dependence on word embedding
     - 词向量输入到 BILSTM层 ，然后输出值是这句话每个标签的预测分数，这些分数便是 CEF层 的输入，其实没有CRF层我们也可以训练 BILSTM，但是我们就不能保证每次预测的都是对的，因为它有可能胡来，比如第一个预测的是B-PER，下一个预测的是B-ORG，这就不符合自然语言的规则了，所以我们加入了CRF这一层，用来约束这些标签，它可以自动地去学习这些约束。
       那么CRF是怎么学习这些约束的呢？
       简单地说就是计算每个标签下一个标签地概率，概率大就有可能出现这样的标签，概率小就不会出现了。
   -  transformer
     - 虽然 RNN 在建模序列方面非常强大，但它们的顺序性本质意味着它们训练起来非常**缓慢**，因为长句需要更多的处理步骤，并且其**繁复循环的结构**也使训练难上加难。
     - Transformer 不需要循环，而是并行处理序列中的所有单词或符号，同时利用自醒机制将上下文与较远的单词结合起来。 通过并行处理所有单词，并让每个单词在多个处理步骤中处理句子中的其他单词，使 Transformer 的训练速度比起复制模型要快得多。
     - self-attention; 'It' has very strong relations to the word 'animal'; encoder and decoder
     - ![Alt text](./1546611996475.png)
     - [图片]![Alt text](./1547456641633.png)
     - [图片]![Alt text](./1547456651907.png)
     - [图片]![Alt text](./1547456660852.png)
     - [图片]![Alt text](./1547456669607.png)
     - [图片]![Alt text](./1547456675037.png)


### 过拟合与欠拟合
> 《深度学习》 5.2 容量、过拟合和欠拟合

- **欠拟合**指模型不能在**训练集**上获得足够低的**训练误差**；
- **过拟合**指模型的**训练误差**与**测试误差**（泛化误差）之间差距过大；
  - 反映在**评价指标**上，就是模型在训练集上表现良好，但是在测试集和新数据上表现一般（**泛化能力差**）；

#### 降低过拟合风险的方法
> 所有为了**减少测试误差**的策略统称为**正则化方法**，这些方法可能会以增大训练误差为代价。

- **数据增强**
  - 图像：平移、旋转、缩放
  - 利用**生成对抗网络**（GAN）生成新数据
  - NLP：分句拼接、利用机器翻译生成新数据
- **降低模型复杂度**
  - 神经网络：减少网络层、神经元个数
  - 决策树：降低树的深度、剪枝
  - ...
- **权值约束**（添加正则化项）
  - L1 正则化
  - L2 正则化
- **集成学习**
  - 神经网络：Dropout
  - 决策树：随机森林、GBDT
- **提前终止**
- **交叉验证**

#### 降低欠拟合风险的方法
- 加入新的特征
  - 交叉特征、多项式特征、...
  - 深度学习：因子分解机、Deep-Crossing、自编码器
- 增加模型复杂度
  - 线性模型：添加高次项
  - 神经网络：增加网络层数、神经元个数
- 减小正则化项的系数
  - 添加正则化项是为了限制模型的学习能力，减小正则化项的系数则可以放宽这个限制
  - 模型通常更倾向于更大的权重，更大的权重可以使模型更好的拟合数据


### 反向传播算法

#### 反向传播的作用/目的/本质
- **反向传播概述**：

  **梯度下降法**中需要利用损失函数对所有参数的梯度来寻找局部最小值点；而**反向传播算法**就是用于计算该梯度的具体方法，其本质是利用**chain rule**对每个参数求偏导。

### 激活函数

#### 激活函数的作用——为什么要使用非线性激活函数？
- 使用**激活函数**的目的是为了向网络中加入**非线性因素**；加强网络的表示能力，解决**线性模型**无法解决的问题

    > [神经网络激励函数的作用是什么？有没有形象的解释？](https://www.zhihu.com/question/22334626) - 知乎 

**为什么加入非线性因素能够加强网络的表示能力？——神经网络的万能近似定理**
- 神经网络的万能近似定理认为主要神经网络具有至少一个非线性隐藏层，那么只要给予网络足够数量的隐藏单元，它就可以以任意的精度来近似任何**从一个有限维空间到另一个有限维空间**的函数。
- 如果不使用非线性激活函数，那么每一层输出都是上层输入的**线性组合**；

  此时无论网络有多少层，其整体也将是线性的，这会导致失去万能近似的性质

  > 《深度学习》 6.4.1 万能近似性质和深度；
- 但仅**部分层是纯线性**是可以接受的，这有助于**减少网络中的参数**。

  > 《深度学习》 6.3.3 其他隐藏单元

#### `ReLU` 相比 `sigmoid` 的优势 (3)

1. **避免梯度消失**
    - `sigmoid`函数在输入取绝对值非常大的正值或负值时会出现**饱和**现象——在图像上表现为变得很平，此时函数会对输入的微小变化不敏感——从而造成梯度消失；
    - `ReLU` 的导数始终是一个常数——负半区为 0，正半区为 1——所以不会发生梯度消失现象
2. **减缓过拟合**
    - `ReLU` 在负半区的输出为 0。一旦神经元的激活值进入负半区，那么该激活值就不会产生梯度/不会被训练，造成了网络的稀疏性——**稀疏激活**
    - 这有助于减少参数的相互依赖，缓解过拟合问题的发生
3. **加速计算**
    - `ReLU` 的求导不涉及浮点运算，所以速度更快

**为什么 ReLU 不是全程可微/可导也能用于基于梯度的学习？**
- 虽然从数学的角度看 ReLU 在 0 点不可导，因为它的左导数和右导数不相等；
- 但是在实现时通常会返回左导数或右导数的其中一个，而不是报告一个导数不存在的错误。从而避免了这个问题


### 正则化

#### Batch Normalization（批标准化）
- BN 是一种**正则化**方法（减少泛化误差），主要作用有：
    - **加速网络的训练**（缓解梯度消失，支持更大的学习率）
    - **防止过拟合**
    - 降低了**参数初始化**的要求。
    - 正向传播中f2=f1(wT∗x+b)，那么反向传播中，∂f2∂x=∂f2∂f1w反向传播式子中有ww的存在，所以w的大小影响了梯度的消失和爆炸，batchnorm就是通过对每一层的输出规范为均值和方差一致的方法，**消除了w带来的放大缩小**的影响，进而解决梯度消失和爆炸的问题，或者可以理解为BN将输出从饱和区拉倒了非饱和区


#### 动机
- **训练的本质是学习数据分布**。如果训练数据与测试数据的分布不同会**降低**模型的**泛化能力**。因此，应该在开始训练前对所有输入数据做归一化处理。
- 而在神经网络中，因为**每个隐层**的参数不同，会使下一层的输入发生变化，从而导致每一批数据的分布也发生改变；**致使**网络在每次迭代中都需要拟合不同的数据分布，增大了网络的训练难度与**过拟合**的风险。

#### 基本原理
- BN 方法会针对**每一批数据**，在**网络的每一层输入**之前增加**归一化**处理，使输入的均值为 `0`，标准差为 `1`。**目的**是将数据限制在统一的分布下。
- 具体来说，针对每层的第 `k` 个神经元，计算**这一批数据**在第 `k` 个神经元的均值与标准差，然后将归一化后的值作为该神经元的激活值。

### Dropout
> 《深度学习》 7.12 Dropout
#### Bagging 集成方法
- **集成方法**的主要想法是分别训练不同的模型，然后让所有模型**表决**最终的输出。

  集成方法奏效的原因是不同的模型**通常不会**在测试集上产生相同的误差。

  集成模型能至少与它的任一成员表现得一样好。**如果成员的误差是独立的**，集成将显著提升模型的性能。

- **Bagging** 是一种集成策略——具体来说，Bagging 涉及构造 k 个**不同的数据集**。

  每个数据集从原始数据集中**重复采样**构成，和原始数据集具有**相同数量**的样例——这意味着，每个数据集以高概率缺少一些来自原始数据集的例子，还包含若干重复的例子

  > 更具体的，如果采样所得的训练集与原始数据集大小相同，那所得数据集中大概有原始数据集 `2/3` 的实例


**集成方法与神经网络**：
- 神经网络能找到足够多的不同的解，意味着他们可以从模型平均中受益——即使所有模型都在同一数据集上训练。 

  神经网络中**随机初始化**的差异、**批训练数据**的随机选择、**超参数**的差异等**非确定性**实现往往足以使得集成中的不同成员具有**部分独立的误差**。

#### Dropout 策略
- 简单来说，Dropout 通过**参数共享**提供了一种廉价的 Bagging 集成近似—— Dropout 策略相当于集成了包括所有从基础网络除去部分单元后形成的子网络。
- 通常，**隐藏层**的采样概率为 `0.5`，**输入**的采样概率为 `0.8`；超参数也可以采样，但其采样概率一般为 `1`

### 调参
> The loss function is used to optimize your model. This is the function that will get minimized by the optimizer. A metric is used to judge the performance of your model. This is only for you to look at and has nothing to do with the optimization process.

- loss
  - categorical_**crossentropy**（NER）
    - 交叉熵描述了两个概率分布之间的距离，当交叉熵越小说明二者之间越接近。尽管交叉熵刻画的是两个概率分布之间的距离，但是神经网络的输出却不一定是一个概率分布。为此我们常常用Softmax回归将神经网络前向传播得到的结果变成概率分布。
  - Average **NCE** loss(水文)
    - 与其用昂贵的交叉熵损失函数，不如用一种叫NCE损失的近似，理论证明当k值足够大时，两者梯度是接近的。
    - NCE loss的直观想法：把多分类问题转化成二分类。之前计算softmax的时候class数量太大，NCE索性就把分类缩减为二分类问题。之前的问题是计算某个类的归一化概率是多少，二分类的问题是input和label正确匹配的概率是多少。二分类问题群众喜闻乐见，直接上logistic regression估算一下概率。
  - **sparse_softmax_cross_entropy_with_logits**中 lables接受直接的数字标签 
    如[1], [2], [3], [4] （类型只能为int32，int64), 而 **softmax_cross_entropy_with_logits** 中 labels接受one-hot标签 如[1,0,0,0], [0,1,0,0],[0,0,1,0], [0,0,0,1] （类型为int32， int64）,相当sparse_softmax_cross_entropy_with_logits 对标签多做一个one-hot动作


>Tensorflow实现了两种常用与word2vec的loss，sampled softmax和NCE，这两种loss本身可以用于任意分类问题。

>去看学术会议中的各种paper，用SGD的很多，Adam的也不少，还有很多偏爱AdaGrad或者AdaDelta。可能研究员把每个算法都试了一遍，哪个出来的效果好就用哪个了。毕竟paper的重点是突出自己某方面的贡献，其他方面当然是无所不用其极，怎么能输在细节上呢？
>[优化对比](https://www.cnblogs.com/ljygoodgoodstudydaydayup/p/7294671.html)

- optimizer
  - sgd: 在每一次计算之后更新参数，而不需要gd中首先将所有训练集求和，但是这样的算法可能不是每一步都朝着正确的方向，因此容易在最小值附近徘徊，可以缩小学习率迫使收敛，但是通常这种代价很大。![Alt text](./1547017040602.png)
  - adam（NER）
    - Adam that includes "correct" L2 weight decay
  - SGD（水文）
    - 对所有的参数更新使用**同样的learning rate**。对于稀疏数据或者特征，有时对于不经常出现的特征我们可能想更新快一些，对于常出现的特征更新慢一些
    - SGD容易收敛到**局部最优**
  - Adam
    - 一种不同参数**自适应不同学习速率**方法，它利用**梯度的一阶矩估计和二阶矩估计动态调整**每个参数的学习率。
  - 对于稀疏数据，尽量使用学习率可自适应的优化方法
  - SGD通常训练时间更长，但是在好的初始化和学习率调度方案的情况下，结果更可靠
  - 如果在意更快的收敛，并且需要训练较深较复杂的网络时，推荐使用学习率自适应的优化方法。
- metrics



### tensorboard调优
1. 查看 graph 结构
2. 查看 accuracy，weights，biases
3. 修改 code
4. 利用不同learnning_rate和网络结构（几个conv_layer）选择最优模型
5. 用 embedding 进一步查看 error 出处
    ![1547620624961](/assets/images/2019-01-15/1547620624961.png)